{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from utils import *\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define residual block and autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A two-convolutional layer residual block.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, c_in, c_out, k, s=1, p=1, mode='encode'):\n",
    "        assert mode in ['encode', 'decode'], \"Mode must be either 'encode' or 'decode'.\"\n",
    "        super(ResBlock, self).__init__()\n",
    "        if mode == 'encode':\n",
    "            self.conv1 = nn.Conv2d(c_in, c_out, k, s, p)\n",
    "            self.conv2 = nn.Conv2d(c_out, c_out, 3, 1, 1)\n",
    "        elif mode == 'decode':\n",
    "            self.conv1 = nn.ConvTranspose2d(c_in, c_out, k, s, p)\n",
    "            self.conv2 = nn.ConvTranspose2d(c_out, c_out, 3, 1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.BN = nn.BatchNorm2d(c_out)\n",
    "        self.resize = s > 1 or (s == 1 and p == 0) or c_out != c_in\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv1 = self.BN(self.conv1(x))\n",
    "        relu = self.relu(conv1)\n",
    "        conv2 = self.BN(self.conv2(relu))\n",
    "        if self.resize:\n",
    "            x = self.BN(self.conv1(x))\n",
    "        return self.relu(x + conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class Encoder(nn.Module):\n",
    "    \"\n",
    "    Encoder class, mainly consisting of three residual blocks.\n",
    "    \"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.init_conv = nn.Conv2d(3, 48, 3, 3, 0) # 48 10 10\n",
    "        self.BN = nn.BatchNorm2d(48)\n",
    "        self.rb1 = ResBlock(48, 48, 3, 2, 1, 'encode') # 48 5 5\n",
    "        self.rb2 = ResBlock(48, 24, 3, 2, 1, 'encode') # 24 3 3\n",
    "        self.rb3 = ResBlock(24, 24, 2, 1, 0, 'encode') # 24 2 2\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        init_conv = self.relu(self.BN(self.init_conv(inputs)))\n",
    "        rb1 = self.rb1(init_conv)\n",
    "        rb2 = self.rb2(rb1)\n",
    "        rb3 = self.rb3(rb2)\n",
    "        return rb3\n",
    "\"\"\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder class, mainly consisting of three residual blocks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.init_conv = nn.Conv2d(3, 16, 3, 1, 1) # 16 32 32\n",
    "        self.BN = nn.BatchNorm2d(16)\n",
    "        self.rb1 = ResBlock(16, 16, 3, 2, 1, 'encode') # 16 16 16\n",
    "        self.rb2 = ResBlock(16, 32, 3, 1, 1, 'encode') # 32 16 16\n",
    "        self.rb3 = ResBlock(32, 32, 3, 2, 1, 'encode') # 32 8 8\n",
    "        self.rb4 = ResBlock(32, 48, 3, 1, 1, 'encode') # 48 8 8\n",
    "        self.rb5 = ResBlock(48, 48, 3, 2, 1, 'encode') # 48 4 4\n",
    "        self.rb6 = ResBlock(48, 64, 3, 2, 1, 'encode') # 64 2 2\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        init_conv = self.relu(self.BN(self.init_conv(inputs)))\n",
    "        rb1 = self.rb1(init_conv)\n",
    "        rb2 = self.rb2(rb1)\n",
    "        rb3 = self.rb3(rb2)\n",
    "        rb4 = self.rb4(rb3)\n",
    "        rb5 = self.rb5(rb4)\n",
    "        rb6 = self.rb6(rb5)\n",
    "        return rb6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class Decoder(nn.Module):\n",
    "    \"\n",
    "    Decoder class, mainly consisting of two residual blocks.\n",
    "    \"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.rb1 = ResBlock(24, 48, 3, 2, 0, 'decode') # 48 5 5\n",
    "        self.rb2 = ResBlock(48, 24, 5, 3, 0, 'decode') # 24 17 17\n",
    "        self.out_conv = nn.ConvTranspose2d(24, 3, 2, 2, 1) # 3 32 32\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        relu = self.relu(inputs)\n",
    "        rb1 = self.rb1(relu)\n",
    "        rb2 = self.rb2(rb1)\n",
    "        out_conv = self.out_conv(rb2)\n",
    "        output = self.tanh(out_conv)\n",
    "        return output\n",
    "\"\"\"\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder class, mainly consisting of two residual blocks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.rb1 = ResBlock(64, 48, 2, 2, 0, 'decode') # 48 4 4\n",
    "        self.rb2 = ResBlock(48, 48, 2, 2, 0, 'decode') # 48 8 8\n",
    "        self.rb3 = ResBlock(48, 32, 3, 1, 1, 'decode') # 32 8 8\n",
    "        self.rb4 = ResBlock(32, 32, 2, 2, 0, 'decode') # 32 16 16\n",
    "        self.rb5 = ResBlock(32, 16, 3, 1, 1, 'decode') # 16 16 16\n",
    "        self.rb6 = ResBlock(16, 16, 2, 2, 0, 'decode') # 16 32 32\n",
    "        self.out_conv = nn.ConvTranspose2d(16, 3, 3, 1, 1) # 3 32 32\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        rb1 = self.rb1(inputs)\n",
    "        rb2 = self.rb2(rb1)\n",
    "        rb3 = self.rb3(rb2)\n",
    "        rb4 = self.rb4(rb3)\n",
    "        rb5 = self.rb5(rb4)\n",
    "        rb6 = self.rb6(rb5)\n",
    "        out_conv = self.out_conv(rb6)\n",
    "        output = self.tanh(out_conv)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoencoder class, combines encoder and decoder model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    @property\n",
    "    def num_params(self):\n",
    "        model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
    "        num_p = sum([np.prod(p.size()) for p in model_parameters])\n",
    "        return num_p\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters in model: {0}\".format(Autoencoder().num_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = ('init_lr', 'batch_size', 'weight_decay')\n",
    "parameters = OrderedDict(\n",
    "    run = [0.05, 256, 0.001],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RunManager()\n",
    "num_epochs = 150\n",
    "\n",
    "for hparams in RunBuilder.get_runs_from_params(param_names, parameters):\n",
    "\n",
    "    # Instantiate a network model\n",
    "    ae = Autoencoder()\n",
    "\n",
    "    # Construct a DataLoader object with training data\n",
    "    train_loader = DataLoader(train_set, batch_size=hparams.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=hparams.batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=10, shuffle=False)\n",
    "    test_images, _ = next(iter(test_loader))\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = optim.SGD(ae.parameters(), lr=hparams.init_lr, momentum=0.9, weight_decay=hparams.weight_decay)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, 60, 0.1)\n",
    "    \n",
    "    # Setup run instance\n",
    "    m.begin_run(hparams, ae, test_images)\n",
    "    print('Now training model with hyperparameters: init_lr={0}, batch_size={1}, weight_decay={2}'\n",
    "         .format(hparams.init_lr, hparams.batch_size, hparams.weight_decay))\n",
    "    \n",
    "    # Start training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        m.begin_epoch()\n",
    "        \n",
    "        # Train the model\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            images, _ = batch\n",
    "            \n",
    "            # Zero all gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Calculating the loss\n",
    "            preds = ae(images)\n",
    "            loss = F.mse_loss(preds, images)\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                with torch.no_grad():\n",
    "                    val_images, _ = next(iter(val_loader))\n",
    "                    val_preds = ae(val_images)\n",
    "                    val_loss = F.mse_loss(val_preds, val_images)\n",
    "                    m.track_loss(val_loss, val_images.size(0), mode='val')\n",
    "                print('Epoch {0}, iteration {1}: train loss {2}, val loss {3}'.format(epoch+1,\n",
    "                                                                               i*hparams.batch_size,\n",
    "                                                                               round(loss.item(), 6),\n",
    "                                                                               round(val_loss.item(), 6)))\n",
    "            \n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            m.track_loss(loss, images.size(0), mode='train')\n",
    "            \n",
    "        m.end_epoch()\n",
    "    \n",
    "    #torch.save(ae, './models/150epochs_' + str(hparams) + '.pth')\n",
    "    m.end_run()\n",
    "    print(\"Model has finished training.\\n\")\n",
    "    scheduler.step()\n",
    "    \n",
    "m.save('results_final')\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "ae = torch.load('./models/final_best_Run(init_lr=0.05, batch_size=256, weight_decay=0.001).pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Visualising test images...\\n\")\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=10, shuffle=True)\n",
    "images, _ = next(iter(test_loader))\n",
    "print(\"Original images:\")\n",
    "imgviz(images)\n",
    "print(\"Reconstructed images:\")\n",
    "with torch.no_grad():\n",
    "    preds = ae(images)\n",
    "    imgviz(preds)\n",
    "    \n",
    "# Test loss\n",
    "test_loader = DataLoader(test_set, batch_size=len(test_set))\n",
    "for i, batch in enumerate(test_loader):\n",
    "    images, _ = batch\n",
    "    with torch.no_grad():\n",
    "        preds = ae(images)\n",
    "        loss = F.mse_loss(preds, images) # calculates the loss\n",
    "print('Test loss:', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate with Kodak image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(256),\n",
    "     transforms.CenterCrop(256),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "kodak_set = torchvision.datasets.ImageFolder(root='../data/Kodak', transform=transform)\n",
    "kodak_loader = DataLoader(kodak_set, batch_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate with Kodak\n",
    "kodak, _ = next(iter(kodak_loader))\n",
    "print(\"Original Kodak images:\")\n",
    "imgviz(kodak, save_fname='kodak_imgs.png', nrow=8)\n",
    "print(\"Reconstructed Kodak images:\")\n",
    "with torch.no_grad():\n",
    "    kodak_preds = ae(kodak)\n",
    "    imgviz(kodak_preds, save_fname='reconstruced_kodak_imgs.png', nrow=8)\n",
    "    kodak_loss = F.mse_loss(kodak_preds, kodak)\n",
    "    print('Kodak MSE loss:', kodak_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualise losses in graph\n",
    "train_losses = np.array([m.run.data[i]['train loss'] for i in range(2, len(m.run.data))])\n",
    "val_losses = np.array([m.run.data[i]['validation loss'] for i in range(2, len(m.run.data))])\n",
    "epochs = np.array(list(range(3, 151)))\n",
    "\n",
    "figure = plt.figure(figsize=(12,6))\n",
    "plt.plot(epochs, train_losses, 'b-', lw=2, label='Training loss')\n",
    "plt.plot(epochs, val_losses, 'r-', lw=2, label='Validation loss')\n",
    "plt.xlabel('epoch', fontsize=18)\n",
    "plt.ylabel('MSE loss', fontsize=18)\n",
    "plt.title('MSE losses for ResNet autoencoder', fontsize=24)\n",
    "plt.xlim([3,150])\n",
    "plt.legend(fontsize=18)\n",
    "plt.grid('on')\n",
    "plt.savefig('./losses')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
