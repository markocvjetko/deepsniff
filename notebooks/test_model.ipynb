{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configs.pyroot_config as pyroot_config\n",
    "import os\n",
    "from torch.utils.data import default_collate\n",
    "import torch\n",
    "from src.data.mice_dataset import MouseSniffingVideoDatasetMultipleFramesLabeled\n",
    "from src.data.mice_dataset_factory import create_dataset, trails_split\n",
    "import torchvision.transforms.v2 as tt\n",
    "from models.lightning_module import DeepSniff\n",
    "from models.models import MobileNetV3\n",
    "from pytorch_lightning.callbacks import *\n",
    "import random\n",
    "\n",
    "config_paths = pyroot_config.ConfigPaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRANSFORMS\n",
    "loading_transforms=tt.Compose([tt.PILToTensor(),\n",
    "                        tt.Resize([112, 112] ,antialias=True)])\n",
    "                        \n",
    "transforms = tt.Compose([\n",
    "                        tt.ConvertImageDtype(torch.float16),\n",
    "                        tt.Normalize(mean=[0.36], std=[0.2])])\n",
    "\n",
    "\n",
    "transforms_val = tt.Compose([\n",
    "                            tt.ConvertImageDtype(torch.float16),\n",
    "                            tt.Normalize(mean=[0.36], std=[0.2])])\n",
    "\n",
    "### DATASET\n",
    "\n",
    "data_dir = config_paths.data_processed / 'sniff-training-dataset'\n",
    "\n",
    "#list all subdirs\n",
    "trails = [f.path for f in os.scandir(data_dir) if f.is_dir()]\n",
    "#print(trails)\n",
    "\n",
    "#train val test 0.9, 0.1, 0.1\n",
    "trails = random.sample(trails, len(trails))\n",
    "train_trails = trails[:int(0.8*len(trails))][:2]\n",
    "val_trails = trails[int(0.8*len(trails)):int(0.9*len(trails))]\n",
    "test_trails = trails[int(0.9*len(trails)):]\n",
    "\n",
    "#print len\n",
    "print(len(train_trails), len(val_trails), len(test_trails))\n",
    "\n",
    "\n",
    "window_size = 5         # Must be odd number\n",
    "signal_window_size = 1  # Must be odd number\n",
    "\n",
    "train_datasets = []\n",
    "for trail in train_trails:\n",
    "    train_datasets.append(MouseSniffingVideoDatasetMultipleFramesLabeled(root_dir=trail,\n",
    "                                                                        video_path='cropped_frames',\n",
    "                                                                        signal_path='breathing_onsets.txt',\n",
    "                                                                        window_size=window_size,\n",
    "                                                                        signal_window_size=signal_window_size,\n",
    "                                                                        transforms=transforms,\n",
    "                                                                        loading_transforms=loading_transforms,\n",
    "                                                                        load_in_memory=True))\n",
    "train_dataset = torch.utils.data.ConcatDataset(train_datasets)\n",
    "\n",
    "val_datasets = []\n",
    "for trail in val_trails:\n",
    "    val_datasets.append(MouseSniffingVideoDatasetMultipleFramesLabeled(root_dir=trail,\n",
    "                                                                        video_path='cropped_frames',\n",
    "                                                                        signal_path='breathing_onsets.txt',\n",
    "                                                                        window_size=window_size,\n",
    "                                                                        signal_window_size=signal_window_size,\n",
    "                                                                        transforms=transforms_val,\n",
    "                                                                        loading_transforms=loading_transforms,\n",
    "                                                                        load_in_memory=True))\n",
    "val_dataset = torch.utils.data.ConcatDataset(val_datasets)\n",
    "\n",
    "test_datasets = []\n",
    "for trail in test_trails:\n",
    "    test_datasets.append(MouseSniffingVideoDatasetMultipleFramesLabeled(root_dir=trail,\n",
    "                                                                        video_path='cropped_frames',\n",
    "                                                                        signal_path='breathing_onsets.txt',\n",
    "                                                                        window_size=window_size,\n",
    "                                                                        signal_window_size=signal_window_size,\n",
    "                                                                        transforms=transforms_val,\n",
    "                                                                        loading_transforms=loading_transforms,\n",
    "                                                                        load_in_memory=True))\n",
    "test_dataset = torch.utils.data.ConcatDataset(test_datasets)\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = default_collate(batch)\n",
    "    batch[0] = batch[0].squeeze([1,2])\n",
    "    return batch\n",
    "\n",
    "\n",
    "\n",
    "## MODEL\n",
    "\n",
    "#weights models/train/annotated/default_train/-step=840-epoch=14-val_loss=1.6483.ckpt\n",
    "weights = config_paths.project_root / 'models/train/annotated/default_train/-step=1176-epoch=20-val_loss=0.8802.ckpt'\n",
    "n_input_channels = window_size\n",
    "output_dim = signal_window_size\n",
    "\n",
    "network = MobileNetV3(n_input_channels=n_input_channels, output_dim=output_dim, weights=weights)\n",
    "\n",
    "\n",
    "\n",
    "model = DeepSniff.load_from_checkpoint(weights)\n",
    "\n",
    "#subsets of datasetes\n",
    "batch_size = 256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=10, collate_fn=collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=10, collate_fn=collate_fn)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=10, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "sample = next(iter(train_loader))\n",
    "print(sample[0].shape, sample[1].shape)\n",
    "\n",
    "print(sample[0])\n",
    "print(train_dataset[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#inference train loader\n",
    "\n",
    "\n",
    "outputs = []\n",
    "gt = []\n",
    "with torch.no_grad():\n",
    "    for sample in val_loader:\n",
    "        #sample to cuda and as float\n",
    "        gt.append(sample[1])\n",
    "        output = model(sample[0].cuda().float())\n",
    "        outputs.append(output)\n",
    "\n",
    "    gt = torch.cat(gt, dim=0)\n",
    "    outputs = torch.cat(outputs, dim=0)\n",
    "    print(outputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plt size\n",
    "plt.figure(figsize=(30, 10))\n",
    "plt.plot(outputs.squeeze().detach().cpu().numpy())\n",
    "#plt ground truth\n",
    "plt.plot(gt.squeeze().detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# iterate over all models in /workspaces/markoc-haeslerlab/sniff-extraction/models/train/annotated/default_train and plot output\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#inference train loader\n",
    "n_input_channels = window_size\n",
    "output_dim = signal_window_size\n",
    "\n",
    "\n",
    "weights_dir = config_paths.project_root / 'models/train/annotated/default_train'\n",
    "weights_list = [f.path for f in os.scandir(weights_dir) if f.is_file() and f.path.endswith('.ckpt')]\n",
    "#remove checkpoint called best\n",
    "weights_list = [x for x in weights_list if 'best.ckpt' not in x]\n",
    "#sort by epoch\n",
    "weights_list = sorted(weights_list, key=lambda x: int(x.split(\"-epoch=\")[1].split(\"-\")[0]))\n",
    "\n",
    "#weights models/train/annotated/default_train/-step=840-epoch=14-val_loss=1.6483.ckpt\n",
    "for weights in weights_list: \n",
    "\n",
    "\n",
    "    network = MobileNetV3(n_input_channels=n_input_channels, output_dim=output_dim, weights=weights)\n",
    "    model = DeepSniff.load_from_checkpoint(weights)\n",
    "\n",
    "    #data/processed/sniff-training-dataset/220221_RDP043_7\n",
    "\n",
    "    dataset = MouseSniffingVideoDatasetMultipleFramesLabeled(root_dir=trail,\n",
    "                                                                            video_path='cropped_frames',\n",
    "                                                                            signal_path='breathing_onsets.txt',\n",
    "                                                                            window_size=window_size,\n",
    "                                                                            signal_window_size=signal_window_size,\n",
    "                                                                            transforms=transforms_val,\n",
    "                                                                            loading_transforms=loading_transforms,\n",
    "                                                                            load_in_memory=True)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=10, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "    outputs = []\n",
    "    gt = []\n",
    "    with torch.no_grad():\n",
    "        for sample in loader:\n",
    "            #sample to cuda and as float\n",
    "            gt.append(sample[1])\n",
    "            #with sigmoide\n",
    "            output = model(sample[0].cuda().float())\n",
    "            output = torch.sigmoid(output)\n",
    "            outputs.append(output)\n",
    "\n",
    "        gt = torch.cat(gt, dim=0)\n",
    "        outputs = torch.cat(outputs, dim=0)\n",
    "        print(outputs.shape)\n",
    "\n",
    "        #plot\n",
    "        plt.figure(figsize=(30, 5))\n",
    "        #dot dash\n",
    "        plt.plot(outputs.squeeze().detach().cpu().numpy(), linestyle='solid')\n",
    "        #plt ground truth dashed\n",
    "        plt.plot(gt.squeeze().detach().cpu().numpy(), linestyle='dashed')\n",
    "        plt.title(weights)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dir = config_paths.data_processed / 'sniff-training-dataset'\n",
    "\n",
    "#list all subdirs\n",
    "trails = [f.path for f in os.scandir(data_dir) if f.is_dir()]\n",
    "\n",
    "### TRANSFORMS\n",
    "loading_transforms=tt.Compose([tt.PILToTensor(),\n",
    "                        tt.Resize([112, 112] ,antialias=True)])\n",
    "                        \n",
    "transforms = tt.Compose([\n",
    "                        tt.Lambda(lambda x: x.permute(1, 0, 2, 3) ),\n",
    "                        tt.ConvertImageDtype(torch.float16),\n",
    "                        tt.Normalize(mean=[0.36], std=[0.2])])\n",
    "\n",
    "\n",
    "transforms_val = tt.Compose([\n",
    "                            tt.Lambda(lambda x: x.permute(1, 0, 2, 3) ),\n",
    "                            tt.ConvertImageDtype(torch.float16),\n",
    "                            tt.Normalize(mean=[0.36], std=[0.2])])\n",
    "\n",
    "\n",
    "### DATASET\n",
    "datasets = []\n",
    "for trail in trails:\n",
    "    datasets.append(MouseSniffingVideoDatasetMultipleFramesLabeled(root_dir=trail,\n",
    "                                                                        video_path='cropped_frames',\n",
    "                                                                        signal_path='breathing_onsets.txt',\n",
    "                                                                        window_size=window_size,\n",
    "                                                                        signal_window_size=signal_window_size,\n",
    "                                                                        transforms=transforms,\n",
    "                                                                        loading_transforms=loading_transforms,\n",
    "                                                                        load_in_memory=True))\n",
    "train_dataset = torch.utils.data.ConcatDataset(train_datasets)\n",
    "\n",
    "\n",
    "#models/train/annotated/default_train/-step=1288-epoch=22-val_loss=2.9251.ckpt\n",
    "\n",
    "weights = config_paths.project_root / 'models/train/annotated/default_train_3d_conv/-step=612-epoch=05-val_loss=0.5442.ckpt'\n",
    "n_input_channels = window_size\n",
    "model = DeepSniff.load_from_checkpoint(weights)\n",
    "\n",
    "for dataset in datasets:\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=10, collate_fn=collate_fn)\n",
    "\n",
    "    outputs = []\n",
    "    gt = []\n",
    "    with torch.no_grad():\n",
    "        for sample in loader:\n",
    "            #sample to cuda and as float\n",
    "            gt.append(sample[1])\n",
    "            output = model(sample[0].cuda().float())\n",
    "            output = torch.sigmoid(output)\n",
    "            outputs.append(output)\n",
    "\n",
    "        gt = torch.cat(gt, dim=0)\n",
    "        outputs = torch.cat(outputs, dim=0)\n",
    "        print(outputs.shape)\n",
    "\n",
    "        #plot\n",
    "        plt.figure(figsize=(30, 5))\n",
    "        plt.plot(outputs.squeeze().detach().cpu().numpy())\n",
    "        plt.plot(gt.squeeze().detach().cpu().numpy(), linestyle='dashed')\n",
    "        plt.title(dataset.root_dir)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
